{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOucIfTJnzaPl0jaGtgof+e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KijoSal-dev/AI-future-week6/blob/main/wk6tsk3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using AI to recommend cancer treatments from datasets such as The Cancer Genome Atlas (TCGA) poses significant **ethical challenges related to biases and fairness**. Key **potential biases** include the **underrepresentation of ethnic groups**—notably African Americans, Asians, and Hispanics—in genomic data, which leads to AI models that do not accurately reflect prognostic and therapeutic genetic signatures across diverse populations. For instance, TCGA's predominance of patients with European ancestry creates a racial skew that can cause models to underperform or misclassify the risks and treatment responses in underrepresented groups.\n",
        "\n",
        "Further, **algorithmic biases** may arise from:\n",
        "- Use of historical clinical data reflecting systemic inequities, resulting in AI reinforcing health disparities rather than mitigating them.\n",
        "- Proxy variables in datasets that inadvertently encode race or socioeconomic status, creating unfair prediction shortcuts in AI models.\n",
        "- Data collection practices that mirror existing healthcare access barriers—older individuals and minority groups are often less enrolled in clinical trials, reducing data diversity.\n",
        "\n",
        "**Fairness strategies** to address these biases must encompass several elements:\n",
        "- **Diverse and representative training data**: Actively enriching datasets with multi-ethnic genomic and clinical data to better capture variations relevant to all populations.\n",
        "- **Bias mitigation methods** including pre-processing techniques like reweighting or resampling to correct for underrepresentation, in-processing optimization constraints that penalize discriminatory patterns, and post-processing calibration that equalizes model predictions across subgroups.\n",
        "- Employing **equitable machine learning frameworks** such as PhyloFrame, which adjusts disease signatures by integrating population genomics and functional data to counter ancestral bias and improve prediction accuracy for minority groups.\n",
        "- Ethical oversight focused on transparency, auditing, and continuous evaluation of AI algorithms in healthcare to prevent harm, particularly among marginalized populations.\n",
        "- Recognizing race as a social construct rather than biological fact, distinguishing socioeconomic determinants from genetic factors to avoid perpetuating inequities in AI-based care.\n",
        "\n",
        "In conclusion, ensuring equity in AI-driven personalized cancer medicine requires rigorous attention to dataset diversity, methodological fairness, and continual validation in ancestrally varied cohorts. Without these measures, AI risks amplifying existing healthcare disparities rather than enabling truly inclusive precision oncology.\n"
      ],
      "metadata": {
        "id": "GgPaLkwOqnew"
      }
    }
  ]
}